# Automated-Text-Evaluation-System
Research and Development project on Automated Text Evaluation System.

Text evaluation by computers is not as satisfactory such that when getting evaluated 
by the machine it can score without taking in account for the human errors. Errors such as Substitution when 
writing on the keyboard or transposition where person writing fast can switch two words happens a lot and this 
text gets evaluated to a zero. Because for computers such errors are not known. This leads to a 0/1 scoring can
lead to discrepancy for the person who gave the test.

Our aim was to create a text evaluation system which can conduct fair scoring. Where errors are handled and the 
scoring is done not on the existing 0/1 system but some pseudo scoring basis. This pseudo scoring is much better than the
1/0 model where the computer is not too harsh on the student for a human error while using the keyboard.

Please Refer the Documentation Folder for all documentation regarding the approaches and workflow.

Contributors:

https://github.com/damngamerz 
